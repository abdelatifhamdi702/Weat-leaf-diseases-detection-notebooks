{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wheat Leaves Disease Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset credits: \n",
    "Dataset 1 : https://www.kaggle.com/datasets/olyadgetch/wheat-leaf-dataset\n",
    "Dataset 2 : https://www.kaggle.com/datasets/sinadunk23/behzad-safari-jalal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from functools import partial\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from genetic_algorithm import GeneticAlgorithm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "# from tensorflow.keras.metrics import Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data into tensorflow dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used splitfolders tool to split dataset into training, validation and test directories.\n",
    "\n",
    "$ pip install split-folders\n",
    "\n",
    "$ splitfolders --ratio 0.8 0.1 0.1 -- ../../wheat_leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4150 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        brightness_range=[0.6,1.0],\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Balanced Dataset/train',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\",\n",
    "        # save_to_dir=\"generated_images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brown_rust': 0, 'Healthy': 1, 'Septoria': 2, 'Yellow_rust': 3}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown_rust', 'Healthy', 'Septoria', 'Yellow_rust']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for image_batch, label_batch in train_generator:\n",
    "#     print(label_batch)\n",
    "    print(image_batch.shape)\n",
    "    break\n",
    "#     count+=1\n",
    "#     if count>2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 517 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'Balanced Dataset/val',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 522 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'Balanced Dataset/test',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.23889874 0.27419287 0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  ...\n",
      "  [0.97573537 0.8995788  0.74360454]\n",
      "  [0.96779794 0.8923855  0.73541903]\n",
      "  [0.95986044 0.8851922  0.7272336 ]]\n",
      "\n",
      " [[0.23741047 0.27270457 0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  ...\n",
      "  [0.84824514 0.78382975 0.6122006 ]\n",
      "  [0.83956355 0.7758923  0.603271  ]\n",
      "  [0.8308821  0.7679548  0.59434134]]\n",
      "\n",
      " [[0.2359222  0.2712163  0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  [0.25490198 0.2901961  0.08235294]\n",
      "  ...\n",
      "  [0.72537386 0.66304624 0.48690075]\n",
      "  [0.72140515 0.656597   0.48318005]\n",
      "  [0.71743643 0.6501479  0.4794594 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.42209026 0.34510314 0.02580113]\n",
      "  [0.4168813  0.34039026 0.02456091]\n",
      "  [0.41167238 0.33567744 0.02332068]\n",
      "  ...\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.58507204 0.4815947  0.3476333 ]]\n",
      "\n",
      " [[0.5164561  0.4232209  0.12126009]\n",
      "  [0.52761817 0.4326466  0.1306858 ]\n",
      "  [0.53878015 0.4420723  0.1401115 ]\n",
      "  ...\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.58532006 0.48134664 0.34589696]]\n",
      "\n",
      " [[0.5885523  0.46792105 0.18196349]\n",
      "  [0.5900405  0.46767303 0.18320371]\n",
      "  [0.59152883 0.46742496 0.18444395]\n",
      "  ...\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.5882353  0.4784314  0.3254902 ]\n",
      "  [0.5855681  0.48109862 0.34416068]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in test_generator:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools\n",
    "import itertools\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "n_classes = 4\n",
    "\n",
    "possible_activations = ['relu', 'sigmoid', 'tanh']\n",
    "possible_optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "possible_pooling = ['max', 'average']\n",
    "possible_learning_rates = [0.001, 0.01, 0.1]\n",
    "\n",
    "possible_values = [possible_activations, possible_optimizers, possible_pooling, possible_learning_rates]\n",
    "possible_values = [list(x) if isinstance(x, tuple) else x for x in possible_values]\n",
    "# set genetic algorithm parameters\n",
    "population_size = 5\n",
    "mutation_probability = 0.05\n",
    "crossover_probability = 0.9\n",
    "num_generations = 4\n",
    "tournament_size = 3\n",
    "\n",
    "# create the fitness function\n",
    "def fitness_function(individual):\n",
    "    activation = individual[0]\n",
    "    optimizer = individual[1]\n",
    "    pooling = individual[2]\n",
    "    learning_rate = individual[3]\n",
    "    print(\"Hyperparameters :\", individual)\n",
    "    input_shape = (256, 256, 3)\n",
    "    n_classes = 4\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=activation),\n",
    "        tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=129,\n",
    "        batch_size=32,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=16,\n",
    "        verbose=0,\n",
    "        epochs=5,\n",
    "    )\n",
    "    fitness = history.history[\"accuracy\"][-1]\n",
    "    print(\"accuracy :\", fitness)\n",
    "    return fitness,\n",
    "\n",
    "# create the toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# create a function to generate a random gene\n",
    "def random_gene():\n",
    "    return random.randint(0, len(possible_activations)-1)\n",
    "\n",
    "# create a function to generate a chromosome\n",
    "def create_chromosome(num_genes):\n",
    "    return [random_gene() for _ in range(num_genes)]\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_activation\", random.choice, possible_activations)\n",
    "toolbox.register(\"attr_optimizer\", random.choice, possible_optimizers)\n",
    "toolbox.register(\"attr_pooling\", random.choice, possible_pooling)\n",
    "toolbox.register(\"attr_learning_rate\", random.choice, possible_learning_rates)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_activation, toolbox.attr_optimizer,\n",
    "                  toolbox.attr_pooling, toolbox.attr_learning_rate), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=len(possible_values)-1, indpb=mutation_probability)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "def optimize_hyperparameters():\n",
    "    # create initial population\n",
    "    population = toolbox.population(n=20)\n",
    "    # evaluate initial fitness\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = (fit,)\n",
    "    # start evolution\n",
    "    for g in range(num_generations):\n",
    "        print(f\"Generation {g+1}\")\n",
    "        # select parents\n",
    "        parents = toolbox.select(population, k=n_parents)\n",
    "        # clone parents\n",
    "        offspring = list(map(toolbox.clone, parents))\n",
    "        # apply crossover and mutation\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < crossover_prob:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "        for mutant in offspring:\n",
    "            if random.random() < mutation_prob:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        # evaluate fitness of new individuals\n",
    "        fitnesses = list(map(toolbox.evaluate, offspring))\n",
    "        for ind, fit in zip(offspring, fitnesses):\n",
    "            ind.fitness.values = (fit,)\n",
    "        # select new population\n",
    "        population = toolbox.select(population + offspring, k=population_size)\n",
    "    best_ind = tools.selBest(population, 1)[0]\n",
    "    return best_ind.fitness.values, best_ind\n",
    "\n",
    "\n",
    "best_fitness, best_ind = optimize_hyperparameters()\n",
    "print(\"Best fitness:\", best_fitness)\n",
    "print(\"Best individual:\", best_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.28897523880004883\n"
     ]
    }
   ],
   "source": [
    "    activation = 'relu'\n",
    "    pooling = 'max'\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    input_shape = (256, 256, 3)\n",
    "    n_classes = 4\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=activation),\n",
    "        tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=129,\n",
    "        batch_size=32,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=16,\n",
    "        verbose=0,\n",
    "        epochs=5,\n",
    "    )\n",
    "    fitness = history.history[\"accuracy\"][-1]\n",
    "    print(\"accuracy :\", fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.2768334150314331\n"
     ]
    }
   ],
   "source": [
    "    activation = 'relu'\n",
    "    pooling = 'max'\n",
    "    learning_rate = 0.1\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    input_shape = (256, 256, 3)\n",
    "    n_classes = 4\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        getattr(tf.keras.layers, f\"{pooling.capitalize()}Pooling2D\")((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=activation),\n",
    "        tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=129,\n",
    "        batch_size=32,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=16,\n",
    "        verbose=0,\n",
    "        epochs=5,\n",
    "    )\n",
    "    fitness = history.history[\"accuracy\"][-1]\n",
    "    print(\"accuracy :\", fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
